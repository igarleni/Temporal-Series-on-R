#
rm(list=ls())
library("tseries")


#######
## Data setup
#######
NTest= 12; # Nº Test items (12 months)

# Load data on a vector
data<-scan("SerieTrabajoPractico.dat")

#6 years, monthly = 72 items. Frequency should be 12 because we are
# talking about years
serie<- ts(data, frequency = 12)

#Visualize
plot(decompose(serie))

# Apply log function to solve non-seasonality variance
#serie.log<- log(serie);

# Visualize again
#plot(decompose(serie))


##################
## Test and training division
##################
serieTr<- serie[1:(length(serie)-NTest)];
tiempoTr<- 1:length(serieTr)
serieTs<- serie[(length(serie)-NTest+1):length(serie)];
tiempoTs<- (tiempoTr[length(tiempoTr)]+1):(tiempoTr[length(tiempoTr)]+NTest);

plot.ts(serieTr, xlim=c(1, tiempoTs[length(tiempoTs)]))
lines(tiempoTs, serieTs, col="red")


####################
# Trend's modeling and removal
####################
 ##Deleting Trend by linear Model Approximation. Looks like linear
#Hypothesis: Linear Model x= a + b*t (x=serie; t=time; a,b=parameters we want to estimate)
parametros.H1 <- lm (serieTr ~ tiempoTr) # Generate model

#Estimate the Trend....
# On train
TendEstimadaTr.H1<-parametros.H1$coefficients[1]+tiempoTr*parametros.H1$coefficients[2] 
# on test
TendEstimadaTs.H1<-parametros.H1$coefficients[1]+tiempoTs*parametros.H1$coefficients[2] 

#Show estimated Test and Train Trend (with real values on background)
plot.ts(serieTr, xlim=c(1, tiempoTs[length(tiempoTs)]))
lines(tiempoTr, TendEstimadaTr.H1, col="blue")
lines(tiempoTs, serieTs, col="red")
lines(tiempoTs, TendEstimadaTs.H1, col="green")

#Calculate Residual Sum of Squares (RRS)
RSS.tendencia.H1= sum( (parametros.H1$residuals)^2);

#Testing the hypotesis with jarque-bera test (p-value)
JBTr <- jarque.bera.test(parametros.H1$residuals)
JBTs <- jarque.bera.test(TendEstimadaTs.H1 - serieTs)

#Its not neccessary to delete Trend, all Tests works

#Delete Trend
#serieTr.SinTend.H1<- serieTr-TendEstimadaTr.H1;
#serieTs.SinTend.H1<- serieTs-TendEstimadaTs.H1;

#Plot new Temporal Serie (without Trend)
#plot.ts(serieTr.SinTend.H1, xlim=c(1, tiempoTs[length(tiempoTs)]))
#lines(tiempoTs, serieTs.SinTend.H1, col="red")

##################
## Seasonality modeling and removal
##################
#Check Seasonality 
acf(serie)
#We can see that there is a seasonality

#Calculate Seasonality
k<- 12; # seasonality = 12, because we are working with years and months
Estacionalidad <- rep(0,k)
for (i in 1:k)
{
  Estacionalidad[i] <- mean(serie[seq(i,length(serie),by = k)])
}
Estacionalidad.rep <- rep(Estacionalidad, ceiling (length(serie)/k))
plot.ts(as.vector(serie))
lines(Estacionalidad.rep, col = "green")

#Delete seasonality
aux<-rep(Estacionalidad, length(serieTr)/length(Estacionalidad));
serieTr.SinEst.H1<- serieTr-aux;
serieTs.SinEst.H1<- serieTs-Estacionalidad;
serie.SinEst.H1 <- serie - Estacionalidad.rep;

#Plot new Temporal Serie (without Trend or Seasonality)
plot.ts(serieTr.SinEst.H1, xlim=c(1, tiempoTs[length(tiempoTs)]))
lines(tiempoTs, serieTs.SinEst.H1, col="red")

######
## Stationarity
######
acf(serie.SinEst.H1)
#Is Stationarity, no need treatment


#########
## ARIMA model
#########
acf(serie.SinEst.H1)
pacf(serie.SinEst.H1)


#Generate ARIMA models
modelo.1200<- arima(serieTr.SinEst.H1, order=c(12, 0, 0))
modelo.200<- arima(serieTr.SinEst.H1, order=c(2, 0, 0))

##############
#####ARIMA (12,0,0)
#Calculate the new adjusted values by adding residuals to original serie
valoresAjustados.1200<- serieTr.SinEst.H1+modelo.1200$residuals; 
valoresAjustados.1200<- valoresAjustados.1200 + Estacionalidad; # Add seasonality

#Predict new values, by using the model generated by Test data
# NTest = 12, the 12 next items that we think will appear.
Predicciones.1200<- predict(modelo.1200, n.ahead = NTest); 
valoresPredichos.1200<- Predicciones.1200$pred + Estacionalidad; # Add seasonality

#Compare the prediction with serieTs.SinEst.H1 (Test values, real "future items")
# by calculate RSS acumulated on the adjusted train data and test
#RSS on train
errorTr.1200<- sum((modelo.1200$residuals)^2);
#RSS on test
errorTs.1200<- sum((valoresPredichos.1200-serieTs)^2);

cat("Error en ajuste con ARIMA(12, 0, 0): ", errorTr.1200, "\n")
cat("Error en la prediccion de test con ARIMA(12, 0, 0): ", errorTs.1200, "\n")

# Visualize results
plot.ts(as.vector(serieTr), xlim=c(1, tiempoTs[length(tiempoTs)]))
lines(valoresAjustados.1200, col="blue")
lines(tiempoTs, serieTs, col="red")
lines(tiempoTs, valoresPredichos.1200, col="green")

# Calculamos el error de prediccion
ErrorMedio<- sum( abs(serieTs-valoresPredichos.1200) )
cat("El error medio en la prediccion es de ", ErrorMedio)

##############
#####ARIMA (2,0,0)
#Calculate the new adjusted values by adding residuals to original serie
valoresAjustados.200<- serieTr.SinEst.H1+modelo.200$residuals; 
valoresAjustados.200<- valoresAjustados.200 + Estacionalidad; # Add seasonality

#Predict new values, by using the model generated by Test data
# NTest = 12, the 12 next items that we think will appear.
Predicciones.200<- predict(modelo.200, n.ahead = NTest); 
valoresPredichos.200<- Predicciones.200$pred + Estacionalidad; # Add seasonality

#Compare the prediction with serieTs.SinEst.H1 (Test values, real "future items")
# by calculate RSS acumulated on the adjusted train data and test
#RSS on train
errorTr.200<- sum((modelo.200$residuals)^2);
#RSS on test
errorTs.200<- sum((valoresPredichos.200-serieTs)^2);

cat("Error en ajuste con ARIMA(2, 0, 0): ", errorTr.200, "\n")
cat("Error en la prediccion de test con ARIMA(12, 0, 0): ", errorTs.200, "\n")

# Visualize results
plot.ts(as.vector(serieTr), xlim=c(1, tiempoTs[length(tiempoTs)]))
lines(valoresAjustados.200, col="blue")
lines(tiempoTs, serieTs, col="red")
lines(tiempoTs, valoresPredichos.200, col="green")

# Calculamos el error de prediccion
ErrorMedio<- sum( abs(serieTs-valoresPredichos.200) )
cat("El error medio en la prediccion es de ", ErrorMedio)


#########
## Quality test for modeling selection
#########
# Tests para la seleccion del modelo y su validacion

##############
#####ARIMA (12,0,0)
#Box-Pierce test (if pvalue > 0.05, its good because residuals are random)
boxtestM1<- Box.test(modelo.1200$residuals) # Test de aleatoriedad de Box-Pierce
cat(c("Box-Pierce p-value=", boxtestM1$p.value, "(if pvalue > 0.05, residuals are random)\n"))

#Jaque-bera test (normality test)(if pvalue >0.05, its residuals are normal)
JB.H1<- jarque.bera.test(modelo.1200$residuals); # Test de normalidad de Jarque Bera
cat(c("Jarque-Bera p-value=", JB.H1$p.value, "(if pvalue >0.05, its residuals are normal)\n"))

#Shapiro-Wilk (normality test)(if pvalue >0.05, its residuals are normal)
SW.H1<- shapiro.test(modelo.1200$residuals); # Test de normalidad de Shapiro-Wilk
cat(c("Shapiro-Wilk p-value=", SW.H1$p.value, "(if pvalue >0.05, its residuals are normal)\n"))

#Residuals Histogram
hist(modelo.1200$residuals, col="blue", prob=T)
lines(density(modelo.1200$residuals))


##############
#####ARIMA (2,0,0)
#Box-Pierce test (if pvalue > 0.05, its good because residuals are random)
boxtestM1<- Box.test(modelo.200$residuals) # Test de aleatoriedad de Box-Pierce
cat(c("Box-Pierce p-value=", boxtestM1$p.value, "(if pvalue > 0.05, residuals are random)\n"))

#Jaque-bera test (normality test)(if pvalue >0.05, its residuals are normal)
JB.H1<- jarque.bera.test(modelo.200$residuals); # Test de normalidad de Jarque Bera
cat(c("Jarque-Bera p-value=", JB.H1$p.value, "(if pvalue >0.05, its residuals are normal)\n"))

#Shapiro-Wilk (normality test)(if pvalue >0.05, its residuals are normal)
SW.H1<- shapiro.test(modelo.200$residuals); # Test de normalidad de Shapiro-Wilk
cat(c("Shapiro-Wilk p-value=", SW.H1$p.value, "(if pvalue >0.05, its residuals are normal)\n"))

#Residuals Histogram
hist(modelo.200$residuals, col="blue", prob=T)
lines(density(modelo.200$residuals))

